# Перед запуском скопируйте в .env: cp env.example .env
#
# Токен Hugging Face (нужен для gated/private моделей; для публичных — опционально)
HF_TOKEN=
#
# Идентификатор модели на Hugging Face ИЛИ локальный путь, примонтированный в контейнер (например, /data/models/МОЯ_МОДЕЛЬ)
MODEL_NAME=
#
# То, что возвращается в /v1/models как "id", и что можно указывать как model=... в запросах
# Любой удобный id, который будет отображаться в /v1/models и использоваться как "model" в запросах
SERVED_MODEL_NAME=local-model
#
# Параметры vLLM под NVIDIA A5000 24GB
DTYPE=bfloat16
GPU_MEMORY_UTILIZATION=0.85
MAX_MODEL_LEN=8192
TENSOR_PARALLEL_SIZE=1
#
# Опционально: включить авторизацию на прокси (только при использовании --profile api)
API_KEY=

