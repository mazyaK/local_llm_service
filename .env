# Перед запуском скопируйте в .env: cp env.example .env
#
# Токен Hugging Face (нужен для gated/private моделей; для публичных — опционально)
HF_TOKEN=...
#
# Model id на Hugging Face ИЛИ локальный путь, примонтированный в контейнер (например, /data/models/Qwen3-8B)
MODEL_NAME=/data/models/Qwen_Qwen3-8B
#
# То, что возвращается в /v1/models как "id", и что можно указывать как model=... в запросах
SERVED_MODEL_NAME=qwen3-8b
#
# Параметры vLLM под NVIDIA A5000 24GB
DTYPE=bfloat16
GPU_MEMORY_UTILIZATION=0.85
MAX_MODEL_LEN=8192
TENSOR_PARALLEL_SIZE=1
#
# Опционально: включить авторизацию на прокси (только при использовании --profile api)
API_KEY=

OPENAI_API_KEY=
RERANK_API_KEY=